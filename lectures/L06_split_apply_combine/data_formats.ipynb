{
  "metadata": {
    "celltoolbar": "Slideshow",
    "filename": "storage_formats.rst",
    "title": "Storage Formats",
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Storage Formats\n\n**Prerequisites**\n\n- [Intro to DataFrames and Series](../p01_pandas_intro/v01_pandas_intro.ipynb)\n\n\n**Outcomes**\n\n- Understand that data can be saved in various formats  \n- Know where to get help on file input and output  \n- Know when to use csv, xlsx, feather, and sql formats  \n\n\n**Data**\n\n- Results for all NFL games between September 1920 to February 2017  ",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Outline\n\n- [Storage Formats](#Storage-Formats)  \n  - [File Formats](#File-Formats)  \n  - [Writing DataFrames](#Writing-DataFrames)  \n  - [Reading Files into DataFrames](#Reading-Files-into-DataFrames)  \n  - [Practice](#Practice)  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np",
      "metadata": {
        "hide-output": false
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## File Formats\n\nData can be saved in a variety of formats\n\npandas understands how to write and read DataFrames to and from many of\nthese formats\n\nWe defer to the [official\ndocumentation](https://pandas.pydata.org/pandas-docs/stable/io.html)\nfor a full description of how to interact with all the file formats, but\nwill briefly discuss a few of them here",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## CSV\n\n**What is it?** CSVs store data as plain text (strings) where each row is a\nline and columns are separated by `,`",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### CSV: Pros\n\n- Widely used (you should be familiar with it)  \n- Plain text file (can open on any computer, “future proof”)  \n- Can be read from and written to by most data software  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### CSV: Cons\n\n- Not the most efficient way to store or access  \n- No formal standard, so there is room for user interpretation on how to\n  handle edge cases (e.g. what to do about a data field that itself includes\n  a comma)  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### CSV: When to use\n\n- A great default option for most use cases  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## xlsx\n\n**What is it?** xlsx is a binary file format used as Excel’s default.\n",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### xlsx: Pros\n\n- Standard format in many industries  \n- Easy to share with colleagues that use Excel  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### xlsx: Cons\n\n- Quite slow to read/write large amounts of data  \n- Stores both data and *metadata* like styling and display information\n  and even plots. This metadata is not always portable to other file formats\n  or programs.  \n- Non-human readable",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### xlsx: When to use\n\n**When to use**:\n\n- When sharing data with Excel  \n- When you would like special formatting to be applied to the\n  spreadsheet when viewed in Excel  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Parquet\n\n**What is it?** Parquet is a custom binary format designed for efficient reading and\nwriting of data stored in columns.",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Parquet: pros\n\n- *Very* fast  \n- Naturally understands all `dtypes` used by pandas, including\n  multi-index DataFrames  \n- Very common in “big data” systems like Hadoop or Spark  \n- Supports various compression algorithms  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Parquet: Cons\n\n- Binary storage format that is not human-readable  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Parquet: When to use\n\n- If you have “not small” amounts (> 100 MB) of unchanging data that\n  you want to read quickly  \n- If you want to store data in an size-and-time-efficient way that may\n  be accessed by external systems  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Feather\n\n**What is it?** Feather is a custom binary format designed for efficient reading and\nwriting of data stored in columns.",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Feather: Pros\n\n- *Very* fast – even faster than parquet  \n- Naturally understands all `dtypes` used by pandas  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Feather: Cons\n\n- Can only read and write from Python and a handful of other\n  programming languages  \n- New file format (introduced in March ‘16), so most files don’t come\n  in this format  \n- Only supports standard pandas index, so you need to `reset_index`\n  before saving and then `set_index` after loading  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Feather: When to use\n\n- Use as an alternative to Parquet if you need the absolute best read and write\n  speeds for unchanging datasets  \n- Only use when you will not need to access the data in a programming language\n  or software outside of Python, R, and Julia  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## SQL\n\n**What is it?** SQL is a language used to interact with relational\ndatabases… [more info](https://en.wikipedia.org/wiki/SQL)",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### SQL: Pros\n\n- Well established industry standard for handling data  \n- Much of the world’s data is in a SQL database somewhere  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### SQL: Cons\n\n- Complicated: to have full control you need to learn another language\n  (SQL)  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### SQL: When to use\n\n- When reading from or writing to existing SQL databases  \n\n\n**NOTE**: We will likely cover interacting with SQL databases in a later lecture",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## JSON\n\nTODO: check what the S means, might just be \"script\"\n\n**What is is?** JSON is an acronym for \"Javascript serialized object notation\". It is a very common way to store data, especially when interacting with web services.\n\nData is stored almost how we would write a Python `dict` by hand using `{` and `}` to provide  key, value pairs",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### JSON: Pros\n\n- Very commonly used when interacting with websites and web apis\n- Maps naturally into a Python dict\n- Human readable\n- Can store non-tabular data (each record or row can have different keys)",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### JSON: Cons\n\n- Relatively inefficient when stored as an array of records (must repeat column names for every row)\n- Non-binary, so can be slow to read and write\n- Ambiguous for how to represent certain data (array of records, record of arrays by column, record of arrays by row, etc.)",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "[\n    {\"identifier\": 0, \"column_A\": 1, \"column_B\": 2},\n    {\"identifier\": 1, \"column_A\": 1, \"column_B\": 2},\n]\n\n{\n    \"identifier\": [0, 1, ...],\n    \"column_A\": [1, 1, ...],\n    \"column_B\": [2, 2, ...]\n}",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### JSON: When to use\n\n- When recieving data from or preparing data for web APIs\n- When you want to store relatively small amounts of non or semi-structured data",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Writing DataFrames\n\nLet’s now talk about saving a DataFrame to a file.\n\n**Rule of thumb**: To save `df` to a file of type `FOO` use `df.to_FOO`\n\nWe'll test this out for a few of the data formats above using some artificial data",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Note**: by default `df2` will be approximately 10 MB. You can change this by adjusting `wanted_mb` in the cell below",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "np.random.seed(42)  # makes sure we get the same random numbers each time\n\ndf1 = pd.DataFrame(\n    np.random.randint(0, 100, size=(10, 4)),\n    columns=[\"a\", \"b\", \"c\", \"d\"]\n)\n\nwanted_mb = 10  # CHANGE THIS LINE\nnrow = 100000\nncol = int(((wanted_mb * 1024**2) / 8) / nrow)\ndf2 = pd.DataFrame(\n    np.random.rand(nrow, ncol),\n    columns=[\"x{}\".format(i) for i in range(ncol)]\n)\n\nprint(\"df2.shape = \", df2.shape)\nprint(\"df2 is approximately {} MB\".format(df2.memory_usage().sum() / (1024**2)))",
      "metadata": {
        "hide-output": false,
        "tags": []
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### [df.to_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html)\n\nLet’s start with `df.to_csv`\n\nWithout any additional arguments, the `df.to_csv` function will return\na string containing the csv form of the DataFrame:",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# notice the plain text format -- one row per line, columns separated by `'`\nprint(df1.to_csv())",
      "metadata": {
        "hide-output": false,
        "tags": []
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "If we do pass an argument, the first argument will be used as the file name.",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "df1.to_csv(\"df1.csv\")",
      "metadata": {
        "hide-output": false
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Run the cell below to verify that the file was created.",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "import os\n\nos.path.isfile(\"df1.csv\")",
      "metadata": {
        "hide-output": false
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Let’s see how long it takes to save `df2` to a file. (Because of the `%%time` at\nthe top, Jupyter will report the total time to run all code in\nthe cell)",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "%%time\n\ndf2.to_csv(\"df2.csv\")",
      "metadata": {
        "hide-output": false,
        "tags": []
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "As we will see below, this isn’t as fastest file format we could choose.",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### [df.to_excel](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_excel.html)\n\nThe `df.to_excel` method writes a DataFrame to an excel workbook\n\nThe first argument is the name of the file\n\nThe second argument is the name of the sheet in that file (this is optional, and is `Sheet1` by default)",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "df1.to_excel?",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df1.to_excel(\"df1.xlsx\", \"df1\")",
      "metadata": {
        "hide-output": false
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We can write multiple DataFrames to a single workbook, eacn in a different sheet\n\nTo do this we use `pd.ExcelWriter(filename)` and then pass the returned object instead of a file name to `df.to_excel`:",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "with pd.ExcelWriter(\"df1.xlsx\") as writer:\n    df1.to_excel(writer, \"df1\")\n    (df1 + 10).to_excel(writer, \"df1 plus 10\")",
      "metadata": {
        "hide-output": false
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "The\n\n```python\nwith ... as ... :\n```\n\nsyntax used above is an example of a *context manager*",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "We don’t need to understand all the details behind what this means\n(google it if you are curious)\n\nFor our purposes we used it so that Python could:\n\n1. create the `df1.xlsx` file\n2. Ensure that the file remains open while pandas writes the two DataFrames\n3. Close the file when finished to finalize storing data",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "<p style=\"color:red;\">\n\nWARNING:\n\n</p>\n\nSaving `df2` to an excel file takes a very long time.\n\nFor that reason, we will just show the code and hard-code the output\nwe saw when we ran the code.",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "%%time\n\ndf2.to_excel(\"df2.xlsx\")",
      "metadata": {
        "hide-output": false,
        "tags": []
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "```python\n Wall time: 25.7 s\n```\n",
      "metadata": {
        "hide-output": false
      }
    },
    {
      "cell_type": "markdown",
      "source": "### [pyarrow.feather.write_feather](https://arrow.apache.org/docs/python/generated/pyarrow.feather.write_feather.html#pyarrow.feather.write_feather)\n\nAs noted above, the feather file format was developed for very efficient\nreading and writing between Python and your computer\n\nSupport for this format is provided by a separate Python package called `pyarrow`\n\nThis package is not installed by default\n\nIf you do not have it, but would like to install `pyarrow`, uncomment and execute the cell below",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "%pip install pyarrow",
      "metadata": {
        "hide-output": false
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "The parameters for `pyarrow.feather.write_feather` are the DataFrame and file name\n\nLet’s try it out",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "import pyarrow.feather\n\npyarrow.feather.write_feather(df1, \"df1.feather\")",
      "metadata": {
        "hide-output": false
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "%%time\n\npyarrow.feather.write_feather(df2, \"df2.feather\")",
      "metadata": {
        "hide-output": false,
        "tags": []
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "An example timing result:\n\n|format|time|\n|:---------:|:----------------------:|\n|csv|2.66 seconds|\n|xlsx|25.7 seconds|\n|feather|43 milliseconds|\n\nAs you can see, saving this DataFrame in the feather format was far\nfaster than either CSV or Excel.",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "%%time\n\ndf2.to_parquet(\"df2.parquet\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Reading Files into DataFrames\n\nAs with the `df.to_FOO` family of methods, there are similar\n`pd.read_FOO` functions. (Note: they are in defined pandas, not as\nmethods on a DataFrame.)\n\nThese methods have many more options because data storage can be messy or wrong",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "We will explore these in more detail in a separate lecture\n\nFor now, we just want to highlight the differences in how to read data\nfrom each of the file formats\n\nLet’s start by reading the files we just created to verify that they\nmatch the data we began with",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "# notice that index was specified in the first (0th -- why?) column of the file\ndf1_csv = pd.read_csv(\"df1.csv\", index_col=0, usecols=[\"b\", \"d\"])\ndf1_csv.head()",
      "metadata": {
        "hide-output": false,
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df1_xlsx = pd.read_excel(\"df1.xlsx\", \"df1\", index_col=0, nrows=3)\ndf1_xlsx.head()",
      "metadata": {
        "hide-output": false,
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# notice feather already knows what the index is\ndf1_feather = pyarrow.feather.read_feather(\"df1.feather\")\ndf1_feather.head()",
      "metadata": {
        "hide-output": false,
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "%%time\n\npyarrow.feather.read_feather(\"df2.feather\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "%%time\n\npd.read_csv(\"df2.csv\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "%%time\n\npd.read_excel(\"df2.xlsx\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "`pd.read_FOO`functions can read files stored online\n\nTo do this, we pass a URL as the first argument:",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "df1_url = \"https://storage.googleapis.com/workshop_materials/df1.csv\"\ndf1_web = pd.read_csv(df1_url, index_col=0)\ndf1_web.head()",
      "metadata": {
        "hide-output": false
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Practice\n\nNow it’s your turn…",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "In the cell below, the variable `url` contains a web address to a csv\nfile containing the result of all NFL games from September 1920 to\nFebruary 2017\n\nYour task is to do the following:\n\n- Use `pd.read_csv` to read this file into a DataFrame named `nfl`  \n- Print the shape and column names of `nfl`  \n- Save the DataFrame to a file named `nfl.xlsx`  \n- Open the spreadsheet using Excel on your computer  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "If you finish quickly, do some basic analysis of the data. Try to do\nsomething interesting. If you get stuck, here are some suggestions for\nwhat to try:\n\n- Compute the average total points in each game (note, you will need to\n  sum two of the columns to get total points).  \n- Repeat the above calculation, but only for playoff games.  \n- Compute the average score for your favorite team (you’ll need to\n  consider when they were team1 vs team2).  \n- Compute the ratio of “upsets” to total games played. An upset is\n  defined as a team with a lower ELO winning the game.  ",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "url = \"https://raw.githubusercontent.com/fivethirtyeight/nfl-elo-game/\"\nurl = url + \"3488b7d0b46c5f6583679bc40fb3a42d729abd39/data/nfl_games.csv\"\n\n# your code here --- create more cells if necessary",
      "metadata": {
        "hide-output": false
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "pd.read_csv(url)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Cleanup\n\nIf you want to remove the files we just created, run the following cell.",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "def try_remove(file):\n    if os.path.isfile(file):\n        os.remove(file)\n\nfor df in [\"df1\", \"df2\"]:\n    for extension in [\"csv\", \"feather\", \"xlsx\"]:\n        filename = df + \".\" + extension\n        try_remove(filename)",
      "metadata": {
        "hide-output": false
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}